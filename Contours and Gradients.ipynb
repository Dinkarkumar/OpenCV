{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation and Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Let's load a simpple image with 3 black squares\n",
    "image = cv2.imread('./images/shapes_donut.jpg')\n",
    "cv2.imshow(\"Input Image\",image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# GrayScale\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Find Canny Edges\n",
    "edged = cv2.Canny(gray,30,200)\n",
    "cv2.imshow('Canny Edges',edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Finding Contours\n",
    "# Use a copy of your image e.g. edged.copy(), since findcontours alters the image\n",
    "contours, hierarchy = cv2.findContours(edged,cv2.RETR_LIST,cv2.CHAIN_APPROX_NONE)\n",
    "cv2.imshow('Canny Edges After Contouring',edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "print(\"Numbers of Contours found = \"+str(len(contours)))\n",
    "\n",
    "# Draw all contours\n",
    "# Use '-1' as the 3rd parameter to draw all\n",
    "cv2.drawContours(image,contours,-1,(0,0,255),5)\n",
    "\n",
    "cv2.imshow('Contours',image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can sort contours in many ways\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load our image\n",
    "image = cv2.imread('./images/bunchofshapes.jpg')\n",
    "cv2.imshow('0-  Orihinal Image',image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Create a black image with same dimension as our loaded image\n",
    "blank_image = np.zeros((image.shape[0],image.shape[1],3))\n",
    "\n",
    "# Create a copy of our original image\n",
    "original_image = image\n",
    "\n",
    "# Grayscale our image\n",
    "gray_image =  cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Find Canny edges\n",
    "edged = cv2.Canny(gray_image,10,50)\n",
    "cv2.imshow('1 - Canny Edges',edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#Find contours and print how many were found\n",
    "contours , hierarchy = cv2.findContours(edged.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "print('Number of contours found = ',len(contours))\n",
    "\n",
    "#Draw all contours over\n",
    "cv2.drawContours(blank_image,contours,-1,(0,255,0),3)\n",
    "cv2.imshow('2 - All Contours over blank image',blank_image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#Draw all contours\n",
    "cv2.drawContours(image,contours,-1,(0,255,0),3)\n",
    "cv2.imshow('3 - All Contours',image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's now sort by Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Function we'll use to display contoyr area\n",
    "\n",
    "def get_contour_area(contours):\n",
    "    #return the area of all contours as list\n",
    "    all_areas = []\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        all_areas.append(area)\n",
    "    return all_areas\n",
    "\n",
    "# Load our image\n",
    "image = cv2.imread('./images/bunchofshapes.jpg')\n",
    "cv2.imshow('original Image',image)\n",
    "cv2.waitKey(0)\n",
    "original_image = image\n",
    "\n",
    "# Let's print the areas of the contours before sorting\n",
    "print(\"Contour Areas before sorting\")\n",
    "print(get_contour_area(contours))\n",
    "\n",
    "# Sort contours large to small\n",
    "sorted_contours = sorted(contours,key = cv2.contourArea, reverse = True)\n",
    "#sorted_contours = sorted(contours,key = cv2.contourArea,reverse = True)[:3]\n",
    "\n",
    "print(\"Contour Areas after sorting\")\n",
    "print(get_contour_area(sorted_contours))\n",
    "\n",
    "# Iterate over our contours and draw one at a time\n",
    "for c in sorted_contours:\n",
    "    cv2.drawContours(original_image,[c],-1,(255,0,0),3)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.imshow('Conoturs by Area',original_image)\n",
    "    \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Functions we'll use for sorting by position \n",
    "\n",
    "def x_cord_contour(contours):\n",
    "    #Returns the X cordinate for the conotur centroid\n",
    "    if cv2.contourArea(contours) > 10:\n",
    "        M = cv2.moments(contours)\n",
    "        return (int(M['m10']/M['m00']))\n",
    "\n",
    "def label_contour_center(image,c,i):\n",
    "    # Places a red circle on the centres of contours\n",
    "    M = cv2.moments(c)\n",
    "    cx = int(M['m10']/M['m00'])\n",
    "    cy = int(M['m01']/M['m00'])\n",
    "    \n",
    "    # draw the cpontour number on the image\n",
    "    cv2.circle(image,(cx,cy),10,(0,0,255),-1)\n",
    "    return image\n",
    "\n",
    "# Load our image\n",
    "image = cv2.imread('./images/bunchofshapes.jpg')\n",
    "original_image = image.copy()\n",
    "\n",
    "# Computer center of Mass or centroids and draw them on our image\n",
    "for (i,c) in enumerate(contours):\n",
    "    orig = label_contour_center(image,c,i)\n",
    "    \n",
    "cv2.imshow(\"4 - Contour Centers\",image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Sort by left to right using x_cord_contour function\n",
    "contour_left_to_right = sorted(contours,key = x_cord_contour,reverse = False)\n",
    "\n",
    "# Labelling contours left to right\n",
    "\n",
    "for (i,c) in enumerate(contour_left_to_right):\n",
    "    cv2.drawContours(original_image,[c],-1,(0,255,0),5)\n",
    "    M = cv2.moments(c)\n",
    "    cx = int(M['m10']/M['m00'])\n",
    "    cy = int(M['m01']/M['m00'])\n",
    "    cv2.putText(original_image,str(i+1),(cx,cy),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n",
    "    cv2.imshow('6 - Left to Right Contour',original_image)\n",
    "    cv2.waitKey(0)\n",
    "    (x,y,w,h) = cv2.boundingRect(c)\n",
    "    \n",
    "    #Let's now crop each contour and save the image\n",
    "    cropped_contour = original_image[y:y+h,x:x+w]\n",
    "    image_name = \"output_shape_number_\"+str(i+1)+\".jpg\"\n",
    "    print(image_name)\n",
    "    cv2.imwrite(image_name,cropped_contour)\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def x_cord_contour(contours):\n",
    "    #Returns the x-coordinate of the image\n",
    "    if cv2.contourArea(contours)>10:\n",
    "        M = cv2.moments(contours)\n",
    "        return int(M['m10']/M['m00'])\n",
    "\n",
    "def label_contour_center(image,c):\n",
    "    # Places a red circle on the centers of the image\n",
    "    M = cv2.moments(c)\n",
    "    cx = int(M['m10']/M['m00'])\n",
    "    cy = int(M['m01']/M['m00'])\n",
    "    \n",
    "    # draw the cicle on the centers of the image\n",
    "    cv2.circle(image,(cx,cy),10,(255,0,0),-1)\n",
    "    return image\n",
    "\n",
    "# Load our image\n",
    "image = cv2.imread('./images/bunchofshapes.jpg')\n",
    "cv2.imshow('Original Image',image)\n",
    "original_image = image.copy()\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#  Compute center of mass or centroids and draw them on our image\n",
    "for (i,c) in enumerate(contours):\n",
    "    orig = label_contour_center(image,c)\n",
    "    \n",
    "cv2.imshow(\"4 - Contour Centers\",image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#Sort by left to right using our x_cord_contour function\n",
    "contour_left_to_right = sorted(contours,key = x_cord_contour,reverse = False)\n",
    "\n",
    "# Labeling Contours Left to Right\n",
    "for (i,c) in enumerate(contour_left_to_right):\n",
    "    cv2.drawContours(original_image,[c],-1,(0,0,255),3)\n",
    "    M = cv2.moments(c)\n",
    "    cx = int(M['m10']/M['m00'])\n",
    "    cy = int(M['m01']/M['m00'])\n",
    "    cv2.putText(original_image,str(i+1),(cx,cy),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),3)\n",
    "    cv2.imshow('6 - Left to Right Contour',original_image)\n",
    "    cv2.waitKey(0)\n",
    "    (x,y,w,h) = cv2.boundingRect(c)\n",
    "    \n",
    "    # Let's now crop each contour and save these images\n",
    "    cropped_contour = original_image[y:y+h,x:x+w]\n",
    "    image_name = \"output_shape_number_\"+str(i+1)+\".jpg\"\n",
    "    print(image_name)\n",
    "    cv2.imwrite(image_name,cropped_contour)\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximating Contours and Convex Hull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv2.approxPolyDP(contour, Approximation Accuracy , Closed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contour - is the individual contour we wish to approximate\n",
    "# Approximation Accuracy - Important paramter is determining the accuracy of the approximation. Small values give precise-approximations,large \n",
    "# values give more generic approximation. A good rule of thumb is less than 5% of the contour perimeter\n",
    "# Perimeter - a Boolean value that states whether the approximate conntour should be open or closed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Load image and keep a copy\n",
    "image = cv2.imread('./images/1.jpg')\n",
    "orig_image = image.copy()\n",
    "\n",
    "cv2.imshow('Original Image',orig_image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# GrayScale and binarize\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "ret,thresh = cv2.threshold(gray,127,255,cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Find COntours\n",
    "contours , hierarchy = cv2.findContours(thresh.copy(),cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "# Iterate through each contour and compute the bounding rectangle\n",
    "for c in contours:\n",
    "    x,y,w,h = cv2.boundingRect(c)\n",
    "    cv2.rectangle(orig_image,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "    cv2.imshow('Bounding rectangle',orig_image)\n",
    "    \n",
    "cv2.waitKey(0)\n",
    "# Iterate through each contour and compute the approx contour\n",
    "for c in contours:\n",
    "    # Calculate accuracy as a percent of the contour perimeter\n",
    "    accuracy = 0.001*cv2.arcLength(c,True)\n",
    "    approx = cv2.approxPolyDP(c,accuracy,True)\n",
    "    cv2.drawContours(image,[approx],0,(0,255,0),2)\n",
    "    cv2.imshow('Approx Poly DP',image)\n",
    "    \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convex Hull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread('./images/hand.jpg')\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imshow('Original Image',image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Threshold the image\n",
    "ret , thresh = cv2.threshold(gray,176,255,0)\n",
    "\n",
    "\n",
    "# FInd Coontours\n",
    "contours , hierarchy = cv2.findContours(thresh.copy(),cv2.RETR_LIST,cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "# Sort Contours by area and then remove the largest frame contour\n",
    "n = len(contours) -1\n",
    "contours = sorted(contours,key = cv2.contourArea,reverse = False)[:n]\n",
    "\n",
    "# Iterate through contours and draw the convex hull\n",
    "for c in contours:\n",
    "    hull = cv2.convexHull(c)\n",
    "    cv2.drawContours(image,[hull],0,(0,255,0),2)\n",
    "    cv2.imshow('convex hull',image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shape Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv2.matchShapes(contour template,contour,method, method parameter)\n",
    "### Output - match value(lower values means a closer match)\n",
    "#### * Contour Template - This is our reference contour that we're trying to find in the new image\n",
    "#### * Contour - The Individual contour we are checking against\n",
    "#### *method - type of contour matching (1,2,3)\n",
    "#### *Method  Parameter - leave alone as 0.0 (not  fully utilized in python OpenCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the shape template or reference image\n",
    "template = cv2.imread('./images/4star.jpg',0)\n",
    "cv2.imshow('Template',template)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Load the target image with the shapes we're trying to match\n",
    "target = cv2.imread('./images/shapestomatch.jpg',0)\n",
    "\n",
    "# Threshold both images first before finding cv2.findContours\n",
    "ret , thresh1 = cv2.threshold(template,127,255,0)\n",
    "ret , thresh2 = cv2.threshold(target,127,255,0)\n",
    "\n",
    "# Find contours in template\n",
    "contours , hierarchy = cv2.findContours(thresh1,cv2.RETR_CCOMP,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# We need to sort the contours by area so that we can remove the largest \n",
    "# contour which is the image outline\n",
    "sorted_contours = sorted(contours,key = cv2.contourArea,reverse = True)\n",
    "\n",
    "# We extract second largest contour which wiill be our template contour \n",
    "template_contour = contours[1]\n",
    "\n",
    "# Extract contours fromm second target image\n",
    "contours, hierarchy = cv2.findContours(thresh2,cv2.RETR_CCOMP,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "for c in contours:\n",
    "    # Iterate through each contour in the target image and \n",
    "    # use cv2.matchShapes to compare contour shapes\n",
    "    match = cv2.matchShapes(template_contour,c,2,0.0)\n",
    "    print(match)\n",
    "    # If the match value is less than 0.15 we\n",
    "    if match < 0.1:\n",
    "        closest_contour = c\n",
    "    else:\n",
    "        closest_contour = []\n",
    "\n",
    "cv2.drawContours(target,[closest_contour],-1,(0,255,0),3)\n",
    "cv2.imshow('Output',target)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini Project 2 - Identifying Contours by Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "#Load and then gray scale images\n",
    "image = cv2.imread('./images/someshapes.jpg')\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('Original Image',image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "ret,thresh = cv2.threshold(gray,127,255,1)\n",
    "\n",
    "# Extract Contours\n",
    "contours , hierarchy = cv2.findContours(thresh.copy(),cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for cnt in contours:\n",
    "    \n",
    "    #Get Approximate polygons\n",
    "    approx = cv2.approxPolyDP(cnt,0.01*cv2.arcLength(cnt,True),True)\n",
    "    \n",
    "    if len(approx)==3:\n",
    "        shape_name = \"Triangle\"\n",
    "        cv2.drawContours(image,[cnt],0,(0,255,0),-1)\n",
    "        \n",
    "        # Find contour center to place text at the center\n",
    "        M = cv2.moments(cnt)\n",
    "        cx = int(M['m10']/M['m00'])\n",
    "        cy = int(M['m01']/M['m00'])\n",
    "        cv2.putText(image,shape_name,(cx-50,cy),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,0,),1)\n",
    "        \n",
    "    elif len(approx) == 4:\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        M = cv2.moments(cnt)\n",
    "        cx = int(M['m10']/M['m00'])\n",
    "        cy = int(M['m01']/M['m00'])\n",
    "        \n",
    "        # Check to see if 4-side polygon is square or rectangle \n",
    "        # cv2.boundingRect returns the top left and then width and \n",
    "        if abs(w-h) <= 3:\n",
    "            shape_name = \"Square\"\n",
    "            # Find contour center to place text at the center\n",
    "            cv2.drawContours(image,[cnt],0,(0,125,255),-1)\n",
    "            cv2.putText(image,shape_name,(cx-50,cy),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,0,),1)\n",
    "        else:\n",
    "            shape_name = \"Rectangle\"\n",
    "            \n",
    "            #Find contour center to place text at the center\n",
    "            cv2.drawContours(image,[cnt],0,(0,0,255),-1)\n",
    "            M = cv2.moments(cnt)\n",
    "            cx = int(M['m10']/M['m00'])\n",
    "            cy = int(M['m01']/M['m00'])\n",
    "            cv2.putText(image,shape_name,(cx-50,cy),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,0),1)\n",
    "            \n",
    "    elif len(approx) == 10:\n",
    "        shape_name = \"Star\"\n",
    "        cv2.drawContours(image,[cnt],0,(255,255,0),-1)\n",
    "        M = cv2.moments(cnt)\n",
    "        cx = int(M['m10']/M['m00'])\n",
    "        cy = int(M['m01']/M['m00'])\n",
    "        cv2.putText(image,shape_name,(cx-50,cy),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,0,),1)\n",
    "        \n",
    "    elif len(approx)>=15:\n",
    "        shape_name = \"Circle\"\n",
    "        cv2.drawContours(image,[cnt],0,(255,255,0),-1)\n",
    "        M = cv2.moments(cnt)\n",
    "        cx = int(M['m10']/M['m00'])\n",
    "        cy = int(M['m01']/M['m00'])\n",
    "        cv2.putText(image,shape_name,(cx-50,cy),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,0,),1)\n",
    "        \n",
    "    cv2.imshow('Identifying Shapes',image)\n",
    "    cv2.waitKey(0)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Line Detection - Using Hough Lines\n",
    "## cv2.HoughLines(binarized/threshold image, p accuarcy, theta accuracy, threshold)\n",
    "###  Threshold here is the minimum vote for it to be considered a line "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('images/soduku.jpg')\n",
    "\n",
    "# Grayscale and Canny Edges extracted\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray,100,170,apertureSize = 3)\n",
    "\n",
    "#Run HoughLines using a rho accuracy of 1 pixel\n",
    "# theta accuracy a np.pi / 180 which is 1 degree\n",
    "# Our line threshold is set to 240(numbber of points on line)\n",
    "lines = cv2.HoughLines(edges, 1 , np.pi/180,100)\n",
    "\n",
    "# We iterate through each line and convert it to the format \n",
    "# required by cv.lines(i.e. requiring end points)\n",
    "for rho, theta in lines[0]:\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a*rho\n",
    "    y0 = b*rho\n",
    "    \n",
    "    x1 = int(x0 + 1000*(-b))\n",
    "    y1 = int(y0 + 1000*(a))\n",
    "    x2 = int(x0 - 1000*(-b))\n",
    "    y2 = int(y0 - 1000*(a))\n",
    "    cv2.line(image, (x1,y1),(x2,y2),(255,0,0),2)\n",
    "    \n",
    "cv2.imshow('Hough Lines',image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic Hough Lines\n",
    "### cv2.HoughLinesP(binarized image, rho accuracy, theta accuracy, threshold, minimum line length, max line gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(422, 1, 4)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# GrayScale and Canny Edges Extracted\n",
    "images = cv2.imread('images/soduku.jpg',0)\n",
    "#gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(images,100,170,apertureSize = 3)\n",
    "\n",
    "# Again we use the same rho and theta accuracies \n",
    "# however, we specific a minimum vote (pts along line) of 100\n",
    "# and Min line length of 5 pixels and max gap between lines of 10 pixels\n",
    "\n",
    "lines = cv2.HoughLinesP(edges,1,np.pi/180,100,5,10)\n",
    "print(lines.shape)\n",
    "\n",
    "for x1,y1,x2,y2 in lines[0]:\n",
    "    cv2.line(images, (x1,y1),(x2,y2),(0,255,0),3)\n",
    "    \n",
    "cv2.imshow('Probabilistic Hough Lines',images)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blob Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Standard imports \n",
    "import cv2\n",
    "import numpy as np\n",
    "    \n",
    "# Read Image\n",
    "image = cv2.imread('images/Sunflowers.jpg',0)\n",
    "\n",
    "# Set up the detector with default parameters\n",
    "detector = cv2.SimpleBlobDetector_create()\n",
    "\n",
    "# Detect Blobs\n",
    "keypoints = detector.detect(image)\n",
    "# Draw detected blobs as red circles\n",
    "# cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS ensures the size of \n",
    "# the circle corresponds to the size of blob\n",
    "blank = np.zeros((1,1))\n",
    "blobs = cv2.drawKeypoints(image,keypoints,blank,(0,255,255),\n",
    "                         cv2.DRAW_MATCHES_FLAGS_DEFAULT)\n",
    "# Show keypoints\n",
    "cv2.imshow(\"Blobs\",blobs)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
